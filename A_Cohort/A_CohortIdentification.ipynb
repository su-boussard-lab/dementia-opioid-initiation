{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa19f7da-fc8b-4526-8fb7-98878960410e",
   "metadata": {},
   "source": [
    "# Cohort identification \n",
    "1. encounters data till cutoff \n",
    "2. dementia and MCI \n",
    "3. count number of unique patients\n",
    "4. count number of patients aged older than 50\n",
    "5. count number of patients who had opioid medication use before the diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c89056-a7ea-4efe-a364-24c36a1028b6",
   "metadata": {},
   "source": [
    "## environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65e4b2-8c9e-4361-b939-7eda799d4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries \n",
    "# Import standard Python libraries\n",
    "import getpass  \n",
    "import re \n",
    "import json \n",
    "import sys  \n",
    "\n",
    "# Import data analysis and visualization libraries\n",
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Import datetime utilities\n",
    "from datetime import datetime, timedelta  \n",
    "\n",
    "# Import libraries for Google BigQuery\n",
    "import pandas_gbq as pgbq  \n",
    "from google.cloud import bigquery  \n",
    "\n",
    "# Import operating system utilities\n",
    "import os  \n",
    "\n",
    "# Import SQLAlchemy for database connection\n",
    "from sqlalchemy import create_engine  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff57a2-023b-4c17-9f5f-fc763152e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure BigQuery project and environment\n",
    "project_id = ''  # BigQuery project ID\n",
    "client = bigquery.Client(project=project_id)  # Initialize BigQuery client\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''  # Authentication credentials\n",
    "os.environ['GCLOUD_PROJECT'] = project_id  # Set the project environment\n",
    "\n",
    "# Define database and datasets\n",
    "db = \"\"  # Main database\n",
    "stanford_ds = \"\"  # Stanford dataset\n",
    "yh_ds = \"\"  # Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2cef2-d98b-43bb-ab01-1549f8210aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom functions \n",
    "# Save a query result to a BigQuery table\n",
    "def save_table(project_id, yh_ds, new_table_name, query):\n",
    "    table_id = f\"{project_id}.{yh_ds}.{new_table_name}\"  # Full table path\n",
    "    job_config = bigquery.QueryJobConfig(destination=table_id)\n",
    "    job_config.write_disposition = \"WRITE_TRUNCATE\"  # Overwrite the table if it exists\n",
    "    query_job = client.query(query, job_config=job_config)  # Run the query\n",
    "    query_job.result()  # Wait for the query job to complete\n",
    "    print(f\"Query results loaded to the table {table_id}\")\n",
    "\n",
    "# Load a table from BigQuery into a Pandas DataFrame\n",
    "def load_pgbq(project_id, yh_ds, table_name):\n",
    "    sql_query = f\"SELECT * FROM {project_id}.{yh_ds}.{table_name}\"  # Query to fetch all rows\n",
    "    return_df = pgbq.read_gbq(sql_query, dialect=\"standard\")  # Load table as DataFrame\n",
    "    print(f\"{project_id}.{yh_ds}.{table_name} is loaded\")\n",
    "    return return_df\n",
    "\n",
    "# Upload a Pandas DataFrame to BigQuery\n",
    "def upload_pgbq(project_id, yh_ds, table_name, df):\n",
    "    table_id = f\"{yh_ds}.{table_name}\"  # Target table path\n",
    "    pgbq.to_gbq(df, table_id, project_id=project_id, if_exists='replace')  # Upload DataFrame\n",
    "    print(f\"DataFrame is uploaded as {project_id}.{yh_ds}.{table_name}\")\n",
    "\n",
    "# Remove a BigQuery table\n",
    "def remove_table(project_id, yh_ds, table_name):\n",
    "    table_id = f\"{project_id}.{yh_ds}.{table_name}\"  # Full table path\n",
    "    client.delete_table(table_id, not_found_ok=True)  # Delete the table if it exists\n",
    "    print(f\"Deleted table '{table_id}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5edc2ed-090a-4c33-9c63-f03034a9232c",
   "metadata": {},
   "source": [
    "## 1. encounter table til 2024-07-31 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee162cf-ee9d-4456-8403-edc0919ba38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cutoff date for diagnosis and death\n",
    "cut_off_date = '2024-07-31'\n",
    "shc_encounter = 'shc_encounter'\n",
    "# select for patients who have dementia \n",
    "# collect patient information on  age at diagnosis, sex, birth date, ethnicity, death date, deceased status, race\n",
    "# collect diagnosis information on id, name, ICD-10 code, and date \n",
    "# death date was collected both from patient table and external death date (with a priority at patient table death date) \n",
    "sql_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{project_id}.{stanford_ds}.{shc_encounter}`\n",
    "WHERE contact_date <= DATE('{cut_off_date}');\n",
    "\"\"\"\n",
    "\n",
    "#save raw dementia patient table \n",
    "table_name = \"encounter_07312024\"\n",
    "save_table(project_id, yh_ds, table_name, sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e563ea-cc1e-478b-9cd1-c3cd85037f20",
   "metadata": {},
   "source": [
    "## 2. patients with dementia / mild cognitive impairment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5fead-fff6-4a12-a46f-a0c2b3906007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom regex functions \n",
    "# Generate a regex pattern for a single ICD-10 code\n",
    "def generate_regex_icd10(ancestor): \n",
    "    if '.' in ancestor:  # If the code contains a decimal point\n",
    "        split = ancestor.split(\".\")  # Split into major and minor parts\n",
    "        regex_string = f\"{split[0]}\\\\.{split[1]}(\\\\d+)?\"  # Match with optional digits after the minor part\n",
    "    else:\n",
    "        regex_string = f\"{ancestor}(\\\\.\\\\d+)?\"  # Match with optional decimal and digits\n",
    "    return regex_string\n",
    "\n",
    "# Generate a combined regex pattern for a list of ICD-10 codes\n",
    "def generate_sql_regex_icd10s(icd10_list):\n",
    "    string = '^('  # Start regex with ^\n",
    "    for icd10_index in range(len(icd10_list)): \n",
    "        icd10 = icd10_list[icd10_index]\n",
    "        pattern = generate_regex_icd10(icd10)  # Get regex for the current ICD-10 code\n",
    "        string += pattern \n",
    "        if icd10_index < (len(icd10_list) - 1):  # Add '|' if it's not the last code\n",
    "            string += '|'\n",
    "        else:  # Close the regex pattern\n",
    "            string += ')$'\n",
    "    return string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209f5a3-4a2c-44ea-896f-4faf907f0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ICD-10 codes to generate regex for\n",
    "icd10_list = ['F00', 'F01', 'F02', 'F03', 'G30', 'F05.1', 'G31.1', 'G31.84']\n",
    "\n",
    "# Generate the combined regex string\n",
    "regex_string = generate_sql_regex_icd10s(icd10_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cd4c6-5ab6-416f-b5aa-6eb5fc79167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cutoff date for diagnosis and death\n",
    "# select for patients who have dementia \n",
    "# collect patient information on  age at diagnosis, sex, birth date, ethnicity, death date, deceased status, race\n",
    "# collect diagnosis information on id, name, ICD-19 code, and date \n",
    "# death date was collected both from patient table and external death date (with a priority at patient table death date) \n",
    "sql_query = f\"\"\"\n",
    "    SELECT \n",
    "        pat.pat_deid,  -- Patient ID\n",
    "        DATE_DIFF(DATE(diag.start_date), DATE(pat.birth_date), YEAR) AS age_at_diagnosis,  -- Calculate age at diagnosis\n",
    "        pat.sex,  -- Patient's sex\n",
    "        DATETIME(pat.birth_date) AS birth_date,  -- Patient's birth date\n",
    "        pat.ethnic_group,  -- Patient's ethnic group\n",
    "        COALESCE(\n",
    "    SAFE.PARSE_DATETIME('%Y-%m-%d %H:%M:%S', CAST(pat.death_date_ssa AS STRING)),\n",
    "    SAFE.PARSE_DATETIME('%Y-%m-%d %H:%M:%S', CAST(pat.death_date AS STRING)),\n",
    "    SAFE.PARSE_DATETIME('%Y-%m-%d %H:%M:%S', CAST(ext.ext_death_date AS STRING))\n",
    ") AS death_date,  -- Use external death date if internal is missing\n",
    "        COALESCE(pat.deceased, pat.deceased_epic) AS deceased,  \n",
    "        pat.race,  -- Patient's race\n",
    "        diag.dx_id,  -- Diagnosis ID\n",
    "        diag.dx_name,  -- Diagnosis name\n",
    "        diag.icd10,  -- Diagnosis ICD-10 code\n",
    "        DATETIME(diag.start_date) AS diagnosis_date  -- Diagnosis date\n",
    "    FROM `som-nero-phi-boussard.stanfordmed_datalake.shc_diagnosis` AS diag\n",
    "    JOIN `som-nero-phi-boussard.stanfordmed_datalake.shc_patient` AS pat \n",
    "        ON pat.pat_deid = diag.pat_deid  -- Join on patient ID\n",
    "    LEFT JOIN `som-nero-phi-boussard.stanfordmed_datalake.external_death_dates` AS ext \n",
    "        ON pat.pat_deid = ext.pat_deid  -- Include external death dates\n",
    "    WHERE \n",
    "        (\n",
    "            REGEXP_CONTAINS(diag.icd10, r'{regex_string}')  -- Match ICD-10 codes with regex\n",
    "            OR REGEXP_CONTAINS(diag.dx_name, r'^(dementia|Dementia)$')  -- Match diagnosis names with regex\n",
    "        )\n",
    "        AND DATE(diag.start_date) <= DATE('{cut_off_date}')  -- Filter diagnoses before or on the cutoff date\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#save raw dementia patient table \n",
    "table_name = \"dementia_pat_dementia_diagnosis_07312024\"\n",
    "save_table(project_id, yh_ds, table_name, sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5371d-e8d5-4175-8bf3-b48dde8acb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"dementia_pat_dementia_diagnosis_07312024\"\n",
    "df_dementia = load_pgbq(project_id, yh_ds, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49508a3-d872-4e88-85c3-5c413912b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to check for any unexpected inclusion \n",
    "# Extract unique ICD-10 codes and disease names\n",
    "unique_icd10 = df_dementia['icd10'].dropna().unique()  # Remove NaN and get unique ICD-10 codes\n",
    "unique_dx_names = df_dementia['dx_name'].dropna().unique()  # Remove NaN and get unique disease names\n",
    "\n",
    "# Convert to a sorted, readable format\n",
    "unique_icd10 = sorted(unique_icd10)\n",
    "unique_dx_names = sorted(unique_dx_names)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Unique ICD-10 Codes:\")\n",
    "# for code in unique_icd10:\n",
    "#     print(f\"- {code}\")\n",
    "\n",
    "# print(\"\\nUnique Disease Names:\")\n",
    "# for name in unique_dx_names:\n",
    "#     print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2c5b3-bf05-49c1-981b-c9a1bccfc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dementia DataFrame\n",
    "\n",
    "# Create a copy of the DataFrame to preserve the original data\n",
    "filtered_df = df_dementia.copy()\n",
    "\n",
    "# Remove rows with ICD-10 codes indicating family history (codes containing 'Z')\n",
    "filtered_df = filtered_df[~filtered_df['icd10'].str.contains('Z', na=False)]\n",
    "\n",
    "# Remove rows with pseudodementia (diagnoses containing 'Geriatric psychosis')\n",
    "filtered_df = filtered_df[~filtered_df['dx_name'].str.contains('Geriatric psychosis', na=False)]\n",
    "\n",
    "# Print the number of unique patients in the original and filtered DataFrame\n",
    "print(\"Original unique patients:\", df_dementia['pat_deid'].nunique())\n",
    "print(\"Filtered unique patients:\", filtered_df['pat_deid'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbf114-eabe-4e27-9b1c-8ffc9cb2fd87",
   "metadata": {},
   "source": [
    "## 3. patient aged 50-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a93ff-3972-4855-b992-639e42355e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for elders aged between 50 and 100\n",
    "df_dementia_elders = filtered_df[\n",
    "    (filtered_df['age_at_diagnosis'] >= 50) & (filtered_df['age_at_diagnosis'] <= 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d88a1a-4d94-4e56-970c-3ac9012da217",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"number of unique elderly patients in dementia table is\", df_dementia_elders['pat_deid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a178e8f-18d4-4cf9-a1ee-48f9964f9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique patients with a death date\n",
    "num_patients_with_death_date = df_dementia_elders[df_dementia_elders['death_date'].notnull()]['pat_deid'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of unique elderly patients with a death date in the dementia table is\", num_patients_with_death_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37874ec-ee06-40e6-a466-a10c4ee39887",
   "metadata": {},
   "source": [
    "get dementia type \n",
    "1. AD\n",
    "2. fronto-temporal\n",
    "3. vascular\n",
    "4. lewy body\n",
    "5. other types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacd3eb-6b26-4659-b02e-544a57290a47",
   "metadata": {},
   "source": [
    "## 4. Collect type of dementia or MCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587bcab-b5ec-4b0c-987f-7058ae5821b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MCI(ICD10, dx_name):\n",
    "    if 'G31.84' in ICD10:\n",
    "        return 1\n",
    "    elif 'mild cognitive impairment' in dx_name.lower():\n",
    "        return 1 \n",
    "    elif 'mci' in dx_name.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0  \n",
    "\n",
    "def get_AD(ICD10, dx_name):\n",
    "    if 'G30' in ICD10:\n",
    "        return 1\n",
    "    elif 'alzheimer' in dx_name.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0  \n",
    "def get_FTD(ICD10, dx_name):\n",
    "    if 'G31.0' in ICD10:\n",
    "        return 1\n",
    "    elif 'frontotemporal' in dx_name.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0  \n",
    "def get_VD(ICD10, dx_name):\n",
    "    if 'F01' in ICD10:\n",
    "        return 1\n",
    "    elif 'vascular dementia' in dx_name.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0\n",
    "def get_LBD(ICD10, dx_name):\n",
    "    if 'G31.83' in ICD10:\n",
    "        return 1\n",
    "    elif 'lewy body' in dx_name.lower():\n",
    "        return 1 \n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def get_dementia_type(df): \n",
    "    copy_df = df.copy()\n",
    "    copy_df['MCI'] = copy_df.apply(lambda x: get_MCI(x[\"icd10\"], x[\"dx_name\"]), axis=1)\n",
    "    copy_df['AD'] = copy_df.apply(lambda x: get_AD(x[\"icd10\"], x[\"dx_name\"]), axis=1)\n",
    "    copy_df['FTD'] = copy_df.apply(lambda x: get_FTD(x[\"icd10\"], x[\"dx_name\"]), axis=1)\n",
    "    copy_df['VD'] = copy_df.apply(lambda x: get_VD(x[\"icd10\"], x[\"dx_name\"]), axis=1)\n",
    "    copy_df['LBD'] = copy_df.apply(lambda x: get_LBD(x[\"icd10\"], x[\"dx_name\"]), axis=1)\n",
    "    copy_df['other_D'] = np.where((copy_df['MCI'] == 0) & (copy_df['AD'] == 0) & (copy_df['FTD'] == 0) & (copy_df['VD'] == 0) & (copy_df['LBD'] == 0), 1, 0)\n",
    "    copy_df['death_from_diagnosis'] = (copy_df['death_date'] - copy_df['diagnosis_date']).dt.days\n",
    "    return copy_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3a792-3c3e-42d0-9fd9-04eead4a8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dementia_elders_types = get_dementia_type(df_dementia_elders)                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc2eb4-2b42-4418-abb8-4bacb6da71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dementia_elders_types.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10903ae3-dfe9-4209-9413-1988f4174713",
   "metadata": {},
   "source": [
    "## 5. get patient-level dementia/MCI table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04862cd3-b8bd-460e-ace6-fcd9ce3756b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = ['pat_deid']  # Identifier column\n",
    "keep_columns = ['sex', 'birth_date', 'ethnic_group', 'death_date', 'deceased', 'race']  # Columns to retain without aggregation\n",
    "min_columns = ['diagnosis_date', 'age_at_diagnosis']  # to get the age at first diagnosis and first diagnosis date \n",
    "max_columns = ['MCI', 'AD', 'FTD', 'VD', 'LBD', 'other_D', 'death_from_diagnosis']  # checking for at least one diagnosis # death from the first diagnosis \n",
    "\n",
    "# Create an aggregation dictionary\n",
    "agg_dict = {col: 'min' for col in min_columns}  # Assign 'min' aggregation for `min_columns`\n",
    "agg_dict.update({col: 'max' for col in max_columns})  # Assign 'max' aggregation for `max_columns`\n",
    "agg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f721b0a-b3e5-4e4d-a796-cca605856366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data for elders by 'pat_deid' using the defined aggregation rules\n",
    "df_dementia_elders_agg = df_dementia_elders_types.groupby('pat_deid', as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad17fd4-eecc-4ee3-b399-e800808b4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique patient information (IDs and key demographic columns)\n",
    "df_dementia_pat = df_dementia_elders[id_columns + keep_columns].drop_duplicates()\n",
    "\n",
    "# Merge aggregated diagnosis data with patient demographic data\n",
    "df_dementia_first_diagnosis = df_dementia_pat.merge(\n",
    "    df_dementia_elders_agg,  # Aggregated data\n",
    "    on='pat_deid',           # Join on patient ID\n",
    "    how='left'               # Keep all rows from `df_dementia_pat`\n",
    ")\n",
    "\n",
    "# Print the shape of the resulting DataFrame\n",
    "print(\"Shape of the merged DataFrame:\", df_dementia_first_diagnosis.shape)\n",
    "# Count missing values for each column\n",
    "missing_values_count = df_dementia_first_diagnosis.isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc8329-5782-45d1-b0bb-bf26fead2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define the table name and full table ID\n",
    "table_name = 'dementia_pat_first_diagnosis_07312024'\n",
    "table_id = f\"{yh_ds}.{table_name}\"  # Dataset and table name in BigQuery format\n",
    "\n",
    "# Upload the DataFrame to BigQuery\n",
    "pgbq.to_gbq(\n",
    "    df_dementia_first_diagnosis,  # DataFrame to upload\n",
    "    table_id,                     # Destination table ID\n",
    "    project_id=project_id,        # BigQuery project ID\n",
    "    if_exists='replace'           # Replace the table if it already exists\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307e375-16d9-43c9-952c-399b2d7bae59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434212c4-e796-488d-a777-e36ecae02f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## last encounter date and number of encounters \n",
    "# # Define dataset and table names\n",
    "# stanford_ds = \"stanfordmed_datalake\"\n",
    "# yh_ds = \"YH_dementia\"\n",
    "# yh_encounter = \"encounter_07312024\"\n",
    "# yh_cohort = \"dementia_pat_first_diagnosis_07312024\"\n",
    "# yh_new_cohort = \"dementia_pat_last_encounter_07312024\"\n",
    "\n",
    "# # SQL query to create or replace the new table with last encounter date and BMI\n",
    "# sql_query = f\"\"\"\n",
    "# CREATE OR REPLACE TABLE {project_id}.{yh_ds}.{yh_new_cohort} AS\n",
    "\n",
    "# SELECT \n",
    "#     pat.*,  -- Include all columns from the patient cohort\n",
    "#     vc.visits_before,  -- Number of visits before the diagnosis date\n",
    "#     vc.visits_after,  -- Number of visits after the diagnosis date\n",
    "#     vc.last_encounter_date,  -- last encounter date before the cut off date \n",
    "#     bmi_data.last_bmi_before_diagnosis  -- Most recent BMI before diagnosis\n",
    "# FROM `{project_id}.{yh_ds}.{yh_cohort}` AS pat  -- Patient cohort as the main table\n",
    "\n",
    "# LEFT JOIN (\n",
    "#     -- Subquery to calculate visits before/after diagnosis and last encounter date\n",
    "#     SELECT \n",
    "#         enc.pat_deid,  -- Patient ID\n",
    "#         SUM(CASE WHEN TIMESTAMP(enc.contact_date) < TIMESTAMP(cohort.diagnosis_date) THEN 1 ELSE 0 END) AS visits_before,  -- Count visits before diagnosis\n",
    "#         SUM(CASE WHEN TIMESTAMP(enc.contact_date) >= TIMESTAMP(cohort.diagnosis_date) THEN 1 ELSE 0 END) AS visits_after,   -- Count visits after diagnosis\n",
    "#         MAX(CASE WHEN TIMESTAMP(enc.contact_date) <= TIMESTAMP('{cut_off_date}') THEN enc.contact_date END) AS last_encounter_date  -- Last encounter date before the cutoff\n",
    "#     FROM `{project_id}.{yh_ds}.{yh_encounter}` AS enc  -- Encounter data\n",
    "#     JOIN `{project_id}.{yh_ds}.{yh_cohort}` AS cohort  -- Join with patient cohort to access diagnosis date\n",
    "#         ON enc.pat_deid = cohort.pat_deid\n",
    "#     GROUP BY enc.pat_deid, cohort.diagnosis_date  -- Group by patient ID and diagnosis date\n",
    "# ) AS vc ON pat.pat_deid = vc.pat_deid  -- Join the aggregated visit data to the patient table\n",
    "\n",
    "# LEFT JOIN (\n",
    "#     -- Subquery to get the last BMI value before diagnosis\n",
    "#     SELECT \n",
    "#         ranked.pat_deid,  -- Patient ID\n",
    "#         ranked.bmi AS last_bmi_before_diagnosis  -- Last BMI value before diagnosis\n",
    "#     FROM (\n",
    "#         -- Subquery to rank BMI records by contact date\n",
    "#         SELECT \n",
    "#             enc_sub.pat_deid,  -- Patient ID\n",
    "#             enc_sub.bmi,  -- BMI value\n",
    "#             enc_sub.contact_date,  -- Contact date for the BMI record\n",
    "#             ROW_NUMBER() OVER (PARTITION BY enc_sub.pat_deid ORDER BY TIMESTAMP(enc_sub.contact_date) DESC) AS rnk  -- Rank rows by most recent contact date\n",
    "#         FROM `{project_id}.{yh_ds}.{yh_encounter}` AS enc_sub  -- Encounter data\n",
    "#         WHERE enc_sub.bmi IS NOT NULL  -- Include only rows with BMI values\n",
    "#         AND TIMESTAMP(enc_sub.contact_date) < (\n",
    "#             SELECT MIN(cohort_sub.diagnosis_date)  -- Get the earliest diagnosis date for the patient\n",
    "#             FROM `{project_id}.{yh_ds}.{yh_cohort}` AS cohort_sub\n",
    "#             WHERE cohort_sub.pat_deid = enc_sub.pat_deid\n",
    "#         )\n",
    "#     ) AS ranked\n",
    "#     WHERE ranked.rnk = 1  -- Select only the most recent BMI record\n",
    "# ) AS bmi_data ON pat.pat_deid = bmi_data.pat_deid;  -- Join the last BMI data to the patient table\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute the query\n",
    "# query_job = client.query(sql_query)\n",
    "# query_job.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a8cf7-4d5e-41bb-9879-3ec014412598",
   "metadata": {},
   "source": [
    "## 6. get opioid record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979fac1-49af-49d2-acdb-3c602cfeaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get opioid rxnorm id \n",
    "# stanford_ds = \"stanfordmed_datalake\"\n",
    "# yh_ds = \"YH_dementia\"\n",
    "# shc_mapping = \"shc_medication_rxnorm_map\"\n",
    "# yh_op_map = \"opioid_rxnorm\"\n",
    "# sql_query = f\"\"\"\n",
    "# SELECT \n",
    "#     map.med_id, \n",
    "#     op_rxnorm.RxNorm_Code, \n",
    "#     op_rxnorm.Name \n",
    "# FROM {db}.{stanford_ds}.{shc_mapping} map \n",
    "# JOIN {db}.{yh_ds}.{yh_op_map} op_rxnorm ON map.rxcui = op_rxnorm.RxNorm_Code\n",
    "# \"\"\"\n",
    "\n",
    "# table_name = \"opioid_med_id\"\n",
    "# save_table(project_id, yh_ds, table_name, sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0de2d-df6a-460c-b020-0efe5f83eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## SQL query to extract opioid medication records for dementia patients\n",
    "# Define datasets and table names\n",
    "stanford_ds = \"stanfordmed_datalake\"\n",
    "yh_ds = \"YH_dementia\"\n",
    "op_med_id = \"opioid_med_id\"\n",
    "dem_patients = \"dementia_pat_first_diagnosis_07312024\"\n",
    "med_records = \"shc_medication\"\n",
    "\n",
    "# opioid start date from dementia diagnosis - helps us to get the exposure status before or after the diagnosis \n",
    "\n",
    "sql_query = f\"\"\"\n",
    "SELECT \n",
    "    dm_pat.*,  -- All patient data from dementia_pat_last_encounter\n",
    "    \n",
    "    -- Days from opioid start and diagnosis (if negative, exposure before diagnosis) \n",
    "    CASE \n",
    "        WHEN op_med.order_start_time IS NULL THEN NULL\n",
    "        ELSE DATE_DIFF(DATE(op_med.order_start_time), DATE(dm_pat.diagnosis_date), DAY)\n",
    "    END AS op_exposure_from_diagnosis_days,\n",
    "\n",
    "    -- Days from diagnosis to opioid start when order was started after the diagnosis \n",
    "    CASE \n",
    "        WHEN op_med.order_start_time IS NULL THEN NULL\n",
    "        WHEN DATE(op_med.order_start_time) >= DATE(dm_pat.diagnosis_date) THEN DATE_DIFF(DATE(op_med.order_start_time), DATE(dm_pat.diagnosis_date), DAY)\n",
    "        ELSE NULL\n",
    "    END AS post_onset_op_exposure_days,\n",
    "\n",
    "    -- Days between opioid exposure and death when order was started after the diagnosis \n",
    "    CASE \n",
    "        WHEN dm_pat.death_date IS NULL OR op_med.order_start_time IS NULL THEN NULL\n",
    "        WHEN DATE(op_med.order_start_time) >= DATE(dm_pat.diagnosis_date) AND DATE(op_med.order_start_time) <= DATE(dm_pat.death_date) AND DATE(dm_pat.diagnosis_date) <= DATE(dm_pat.death_date) THEN DATE_DIFF(DATE(dm_pat.death_date), DATE(op_med.order_start_time), DAY)\n",
    "        ELSE NULL\n",
    "    END AS post_onset_post_opioid_death_days,\n",
    "\n",
    "    -- Classify opioid strength\n",
    "    CASE \n",
    "        WHEN LOWER(op_med.ingredient) IN ('hydrocodone', 'codeine', 'tramadol') THEN 1  -- Weak opioids\n",
    "        WHEN LOWER(op_med.ingredient) IN ('fentanyl', 'hydromorphone', 'oxycodone', 'morphine', 'methadone', 'meperidine', 'buprenorphine') THEN 2  -- Strong opioids\n",
    "        ELSE 0  -- Non-opioids or undefined\n",
    "    END AS opioid_strength_classification,\n",
    "\n",
    "    -- Medication details\n",
    "    op_med.order_deid,\n",
    "    op_med.pat_enc_csn_deid,\n",
    "    op_med.med_id,\n",
    "    op_med.ingredient, \n",
    "    op_med.medication_name,\n",
    "    op_med.ordering_date, \n",
    "    op_med.order_start_time,\n",
    "    op_med.order_end_time,\n",
    "    op_med.med_route, \n",
    "    op_med.ordering_mode, \n",
    "    op_med.order_class,\n",
    "    op_med.is_administered\n",
    "FROM {db}.{yh_ds}.{dem_patients} dm_pat  -- Dementia patients \n",
    "LEFT JOIN (\n",
    "    -- Join to extract opioid medication records\n",
    "    SELECT \n",
    "        med.pat_deid,\n",
    "        med_id.med_id, \n",
    "        med_id.Name AS ingredient, \n",
    "        med.medication_name AS medication_name,\n",
    "        med.order_deid, \n",
    "        med.pat_enc_csn_deid, \n",
    "        med.ordering_date, \n",
    "        med.order_start_time,\n",
    "        med.order_end_time,\n",
    "        med.med_route, \n",
    "        med.ordering_mode, \n",
    "        med.order_class, \n",
    "        med.is_administered\n",
    "    FROM {db}.{yh_ds}.{op_med_id} med_id\n",
    "    INNER JOIN {db}.{stanford_ds}.{med_records} med ON med_id.med_id = med.medication_id  -- Link opioid ID to medication records\n",
    ") op_med \n",
    "ON dm_pat.pat_deid = op_med.pat_deid\n",
    "WHERE op_med.order_start_time >= DATE_SUB(DATE(dm_pat.diagnosis_date), INTERVAL 1 YEAR)  -- Opioids within 1 year before diagnosis\n",
    "  AND op_med.order_start_time <= '{cut_off_date}';  -- Opioids before the cutoff date\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "new_table_name = \"dementia_op_med_07312024\"\n",
    "save_table(project_id, yh_ds, new_table_name, sql_query )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0488fc9-9f02-40f0-b223-860b6c843fe6",
   "metadata": {},
   "source": [
    "### medication record feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ad594-d757-4265-be67-c98222caa828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset and table names\n",
    "stanford_ds = \"stanfordmed_datalake\"\n",
    "yh_ds = \"YH_dementia\"\n",
    "sql_table = \"dementia_op_med_07312024\"\n",
    "\n",
    "# SQL query to classify opioid exposures relative to diagnosis\n",
    "sql_query = f\"\"\"\n",
    "SELECT *,\n",
    "    -- Flag for opioid exposure within 1 year before diagnosis\n",
    "    CASE \n",
    "        WHEN op_exposure_from_diagnosis_days >= -365 AND op_exposure_from_diagnosis_days < 0 THEN 1  -- Within 1 year before diagnosis\n",
    "        ELSE 0  -- Outside the 1-year window\n",
    "    END AS exposure_within_1_year, \n",
    "\n",
    "    -- Flag for opioid exposure after diagnosis\n",
    "    CASE \n",
    "        WHEN op_exposure_from_diagnosis_days >= 0 THEN 1  -- Exposure on or after diagnosis date\n",
    "        ELSE 0  -- No exposure after diagnosis\n",
    "    END AS exposure_after,\n",
    "\n",
    "    -- Start time for opioid exposure after diagnosis\n",
    "    CASE \n",
    "        WHEN DATETIME(order_start_time) >= DATETIME(diagnosis_date) THEN DATETIME(order_start_time)  -- Exposure starts after diagnosis\n",
    "        WHEN DATETIME(exposure_end_time) >= DATETIME(diagnosis_date) AND DATETIME(order_start_time) <= DATETIME(diagnosis_date) THEN DATETIME(diagnosis_date)  -- Ends after diagnosis but started before\n",
    "        ELSE NULL  -- No exposure after diagnosis\n",
    "    END AS post_onset_exposure_start_time,\n",
    "\n",
    "    -- Start time for opioid exposure before diagnosis\n",
    "    CASE \n",
    "        WHEN DATETIME(order_start_time) <= DATETIME(diagnosis_date) THEN DATETIME(order_start_time)  -- Exposure starts before diagnosis\n",
    "        ELSE NULL  -- No exposure before diagnosis\n",
    "    END AS pre_onset_exposure_start_time,\n",
    "\n",
    "    -- End time for opioid exposure after diagnosis\n",
    "    CASE \n",
    "        WHEN DATETIME(exposure_end_time) >= DATETIME(diagnosis_date) THEN DATETIME(exposure_end_time)  -- Exposure ends after diagnosis\n",
    "        ELSE NULL  -- No exposure after diagnosis\n",
    "    END AS post_onset_exposure_end_time,\n",
    "\n",
    "    -- End time for opioid exposure before diagnosis\n",
    "    CASE \n",
    "        WHEN DATETIME(exposure_end_time) < DATETIME(diagnosis_date) THEN DATETIME(exposure_end_time)  -- Ends before diagnosis\n",
    "        WHEN DATETIME(exposure_end_time) >= DATETIME(diagnosis_date) AND DATETIME(order_start_time) < DATETIME(diagnosis_date) THEN DATETIME(diagnosis_date)  -- Ends after diagnosis but started before\n",
    "        ELSE NULL  -- No exposure before diagnosis\n",
    "    END AS pre_onset_exposure_end_time\n",
    "FROM (\n",
    "    -- Subquery to calculate exposure end time\n",
    "    SELECT *,\n",
    "        CASE \n",
    "            WHEN order_end_time IS NULL THEN DATETIME(order_start_time)  -- Use start time if end time is missing\n",
    "            ELSE DATETIME(order_end_time)  -- Use end time if available\n",
    "        END AS exposure_end_time\n",
    "    FROM {db}.{yh_ds}.{sql_table}  -- Source table with opioid medication records\n",
    ") AS subquery;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "op_med = pgbq.read_gbq(sql_query, dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8da46e-0919-46f6-a155-1fe45c69a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_med.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5daeee-8315-4c4f-b26c-53e54ff00793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate opioid medication records based on specific columns\n",
    "op_med2 = op_med.copy()\n",
    "op_med2 = op_med2.drop_duplicates(\n",
    "    subset=['pat_deid', 'ingredient', 'order_start_time', 'exposure_end_time']\n",
    ")\n",
    "\n",
    "# Calculate the duration of opioid exposure after diagnosis\n",
    "op_med2['post_onset_duration'] = (\n",
    "    op_med2['post_onset_exposure_end_time'] - op_med2['post_onset_exposure_start_time'] \n",
    "    + pd.to_timedelta(1, unit='D')  # Add 1 day to include both start and end dates\n",
    ")\n",
    "\n",
    "# Calculate the duration of opioid exposure before diagnosis\n",
    "op_med2['pre_onset_duration'] = (\n",
    "    op_med2['pre_onset_exposure_end_time'] - op_med2['pre_onset_exposure_start_time'] \n",
    "    + pd.to_timedelta(1, unit='D')  # Add 1 day to include both start and end dates\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb05161-6eb3-41f9-9509-62e128b4b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column groups for aggregation\n",
    "id_columns = ['pat_deid']  # Identifier column\n",
    "keep_columns = ['pat_deid','sex', 'birth_date', 'ethnic_group', 'death_date',\n",
    "       'deceased', 'race', 'diagnosis_date', 'age_at_diagnosis', 'MCI', 'AD',\n",
    "       'FTD', 'VD', 'LBD', 'other_D', 'death_from_diagnosis']\n",
    "min_columns = [\n",
    "    'op_exposure_from_diagnosis_days' , 'post_onset_op_exposure_days', \n",
    "    'pre_onset_exposure_start_time', 'post_onset_exposure_start_time'  # Columns to aggregate by minimum\n",
    "]\n",
    "max_columns = [\n",
    "    'pre_onset_exposure_end_time', 'post_onset_exposure_end_time',\n",
    "    'post_onset_post_opioid_death_days',\n",
    "    'exposure_within_1_year', # for exposure group \n",
    "    'exposure_after', # for exposure group \n",
    "]\n",
    "sum_columns = ['post_onset_duration', 'pre_onset_duration']  # Columns to sum\n",
    "\n",
    "# Create aggregation dictionary\n",
    "agg_dict = {}\n",
    "\n",
    "# Assign 'min' aggregation for min_columns\n",
    "for col in min_columns:\n",
    "    agg_dict[col] = 'min'\n",
    "\n",
    "# Assign 'max' aggregation for max_columns\n",
    "for col in max_columns:\n",
    "    agg_dict[col] = 'max'\n",
    "\n",
    "# Assign 'sum' aggregation for sum_columns\n",
    "for col in sum_columns:\n",
    "    agg_dict[col] = 'sum'\n",
    "\n",
    "# Display the aggregation dictionary\n",
    "agg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747165c7-579d-4cd8-a331-fbdfbb0a4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate opioid medication data by patient ID\n",
    "op_med_agg = op_med2.groupby('pat_deid', as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ab6e9-37cf-42e0-b445-c4963a4ce3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(op_med_agg.post_onset_post_opioid_death_days<=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4232e-45a7-4693-8ea1-6f748a09205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table name\n",
    "table_name = \"dementia_pat_first_diagnosis_07312024\"\n",
    "\n",
    "# Load the table data from BigQuery into a pandas DataFrame\n",
    "df_dementia_first_diagnosis = load_pgbq(project_id, yh_ds, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78465b4-2ace-43f6-9d27-05caa27241a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dementia_first_diagnosis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc421eb-2754-430c-917b-8c8aba3185cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of rows in the DataFrame before dropping rows with null values in 'last_encounter_date'\n",
    "print(df_dementia_first_diagnosis.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dcefd-f602-4fd2-a94c-9d99850dede6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with only the specified columns and remove duplicate rows\n",
    "keep_df = df_dementia_first_diagnosis[keep_columns].drop_duplicates()\n",
    "\n",
    "# Merge the 'keep_df' DataFrame with the aggregated opioid medication data ('op_med_agg')\n",
    "# Join is performed on 'pat_deid' with a left join to retain all rows from 'keep_df'\n",
    "merged_df = keep_df.merge(op_med_agg, on='pat_deid', how='left')\n",
    "\n",
    "# Fill missing values in specific columns with 0\n",
    "merged_df[['exposure_within_1_year', 'exposure_after', 'post_onset_duration', 'pre_onset_duration']] = (\n",
    "    merged_df[['exposure_within_1_year', 'exposure_after', 'post_onset_duration', 'pre_onset_duration']].fillna(0)\n",
    ")\n",
    "\n",
    "# Display all column names in the merged DataFrame\n",
    "merged_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559883a-e7ef-497b-bd79-3c2a45615e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to label exposure groups based on opioid exposure timing\n",
    "def label_exposure_group(df):\n",
    "    within_1yr_col = 'exposure_within_1_year'  # Column indicating exposure within 1 year before diagnosis\n",
    "    after_col = 'exposure_after'  # Column indicating exposure after diagnosis\n",
    "\n",
    "    # Assign labels based on the conditions\n",
    "    if (df[within_1yr_col] != 1) & (df[after_col] == 1):\n",
    "        return 'new user'  # No exposure within 1 year before diagnosis but exposure after diagnosis\n",
    "    elif (df[within_1yr_col] == 1) & (df[after_col] == 1):\n",
    "        return 'consistent user'  # Exposure both within 1 year before and after diagnosis\n",
    "    elif (df[within_1yr_col] != 1) & (df[after_col] != 1):\n",
    "        return 'control'  # No exposure before or after diagnosis\n",
    "    elif (df[within_1yr_col] == 1) & (df[after_col] != 1):\n",
    "        return 'discontinued'  # Exposure within 1 year before diagnosis but no exposure after\n",
    "    else:\n",
    "        return None  # Fallback for unexpected cases\n",
    "\n",
    "# Apply the labeling function to each row of the DataFrame\n",
    "merged_df = merged_df.assign(\n",
    "    exposure_group=merged_df.apply(label_exposure_group, axis=1)  # Create a new 'exposure_group' column\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803b26f-3d09-46b0-ad21-59c5b2e3de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (merged_df.exposure_group.value_counts())\n",
    "missing_values = merged_df['exposure_group'].isnull().sum()\n",
    "\n",
    "print(f\"Number of missing values in 'exposure_group': {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b48c7a-b189-4011-8162-d618c8f47f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(merged_df[merged_df.exposure_group.isin(['consistent user','new user'])].post_onset_post_opioid_death_days<=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99661140-fcda-49da-8270-9ae511e3ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['pre_onset_duration'] = pd.to_timedelta(merged_df['pre_onset_duration'])\n",
    "merged_df['post_onset_duration'] = pd.to_timedelta(merged_df['post_onset_duration'])\n",
    "\n",
    "# Round up 'pre_diagnosis_duration' to the nearest day\n",
    "merged_df['pre_onset_duration'] = merged_df['pre_onset_duration'].apply(lambda x: x.ceil('D'))\n",
    "\n",
    "# Round up 'post_diagnosis_duration' to the nearest day\n",
    "merged_df['post_onset_duration'] = merged_df['post_onset_duration'].apply(lambda x: x.ceil('D'))\n",
    "\n",
    "# Extract the number of days from 'pre_diagnosis_duration'\n",
    "merged_df['pre_onset_duration'] = merged_df['pre_onset_duration'].dt.days\n",
    "\n",
    "# Extract the number of days from 'post_diagnosis_duration'\n",
    "merged_df['post_onset_duration'] = merged_df['post_onset_duration'].dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fe06f-42e4-4dd0-b456-23d6e5d4ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_pgbq(project_id, yh_ds, 'dementia_pat_exposure_group_07312024', merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1a9e7-9391-4834-a188-78dda5ef63e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c37ca3-1c10-4ce2-ad37-66af3657626e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058d63a-851e-4977-b268-bf4b98b281f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
