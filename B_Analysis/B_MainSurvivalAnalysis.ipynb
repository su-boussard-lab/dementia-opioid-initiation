{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971184d0-9a4a-4f51-badf-8b0e72aa7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for data analysis and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical summaries\n",
    "from tableone import TableOne\n",
    "\n",
    "# BigQuery interaction\n",
    "import pandas_gbq as pgbq\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Database connections\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Utilities for date/time manipulation\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set up inline plotting for Jupyter Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a2dbe-6246-413a-b0f6-8a7d81817b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configurations for Big Query\n",
    "project_id = '' # Location of stride datalake\n",
    "client = bigquery.Client(project=project_id) # Set project to project_id\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''\n",
    "os.environ['GCLOUD_PROJECT'] = \"\" # specify environment\n",
    "db = \"\" # Define the database\n",
    "stanford_ds = \"\"\n",
    "yh_ds = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d3292-fbdd-413e-b565-90bfdec88cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(project_id, yh_ds, new_table_name, query):\n",
    "    table_id = f\"{project_id}.{yh_ds}.{new_table_name}\"\n",
    "    job_config = bigquery.QueryJobConfig(destination=table_id)\n",
    "    job_config.write_disposition = \"WRITE_TRUNCATE\"\n",
    "    # Start the query, passing in the extra configuration.\n",
    "    query_job = client.query(query, job_config=job_config)  # Make an API request.\n",
    "    query_job.result()  # Wait for the job to complete.\n",
    "    print(\"Query results loaded to the table {}\".format(table_id))  \n",
    "def load_pgbq(project_id, yh_ds, table_name):\n",
    "    sql_query = f\"SELECT * FROM {project_id}.{yh_ds}.{table_name}\"\n",
    "    return_df = pgbq.read_gbq(sql_query, dialect=\"standard\")\n",
    "    print (f\"{project_id}.{yh_ds}.{table_name}\", \"is loaded\") \n",
    "    return return_df\n",
    "def upload_pgbq(project_id, yh_ds, table_name, df):\n",
    "    table_id = f\"{yh_ds}.{table_name}\"\n",
    "    pgbq.to_gbq(df, table_id, project_id=project_id)\n",
    "    print (\"dataframe\", df, \"is uploaded as\", f\"{project_id}.{yh_ds}.{table_name}\") \n",
    "def remove_table(project_id, yh_ds, table_name):\n",
    "    client = bigquery.Client()\n",
    "    table_id = f\"{project_id}.{yh_ds}.{table_name}\"\n",
    "    client.delete_table(table_id, not_found_ok=True)  # Make an API request.\n",
    "    print(\"Deleted table '{}'.\".format(table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd6c72-777b-450d-8866-c6b3bd023efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_death_duration_column(death_after_exposure,  observation_days): \n",
    "    if pd.isna(death_after_exposure):\n",
    "        return observation_days\n",
    "    elif death_after_exposure > observation_days: # when the patient died after the observation cut off \n",
    "        return observation_days \n",
    "    elif death_after_exposure <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return death_after_exposure \n",
    "def get_death_outcome_column(death_after_exposure, observation_days): \n",
    "    if pd.isna(death_after_exposure):\n",
    "        return False\n",
    "    elif death_after_exposure > observation_days: \n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627a58e-2870-454f-8de2-7160de8a7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df = pd.read_csv(\"../A_Cohort/final_cohort_07312024.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3934a-12b5-41dc-9281-ccf15414965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = cohort_df[cohort_df.exposure_group.isin(['new user', 'consistent user'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe4c0b-4c91-46ef-bcbe-0200386b005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping 'deceased' column to boolean values\n",
    "death_mapping_dict = {'Y': True, 'N': False}\n",
    "df_comparison = df_comparison.assign(\n",
    "    deceased_boolean=df_comparison['deceased'].map(death_mapping_dict)\n",
    ")\n",
    "\n",
    "# Mapping 'exposure_group' column to numeric values\n",
    "exposure_mapping_dict = {'new user': 1, 'consistent user': 0}\n",
    "df_comparison = df_comparison.assign(\n",
    "    exposure_float=df_comparison['exposure_group'].map(exposure_mapping_dict)\n",
    ")\n",
    "\n",
    "# Display the count of each category in the 'exposure_group' column\n",
    "exposure_group_counts = df_comparison['exposure_group'].value_counts()\n",
    "print(exposure_group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bb19b-b9de-4d60-80d4-b8f9e083ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "medication_table_name = 'dementia_medication_categories'\n",
    "medication_table_id = f\"{db}.{yh_ds}.{medication_table_name}\"\n",
    "medication_table = client.get_table(medication_table_id)\n",
    "\n",
    "comorbidity_table_name = 'dementia_comorbidity_categories_aggregated'\n",
    "comorbidity_table_id = f\"{db}.{yh_ds}.{comorbidity_table_name}\"\n",
    "comorbidity_table = client.get_table(comorbidity_table_id)\n",
    "\n",
    "comorbidity_before_exposure_table_name = 'dementia_comorbidity_categories_before_exposure_aggregated'\n",
    "comorbidity_before_exposure_table_id = f\"{db}.{yh_ds}.{comorbidity_before_exposure_table_name}\"\n",
    "comorbidity_before_exposure_table = client.get_table(comorbidity_before_exposure_table_id)\n",
    "\n",
    "# Get the list of column names\n",
    "comorbidity_column_names = [schema_field.name for schema_field in comorbidity_table.schema]\n",
    "comorbidity_before_exposure_table_column_names = [schema_field.name for schema_field in comorbidity_before_exposure_table.schema]\n",
    "medication_column_names = [schema_field.name for schema_field in medication_table.schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d7d3d-8ed1-434f-a9ed-af33e168d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_comparison.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1cc2f-1e43-46af-95ca-ce3f142a1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Feature engineering: Imputation and BMI categorization\n",
    "df_imputed = df_comparison.copy()\n",
    "\n",
    "# Convert 'last_bmi_before_exposure' to numeric, handling invalid values\n",
    "df_imputed['last_bmi_before_exposure'] = pd.to_numeric(\n",
    "    df_imputed['last_bmi_before_exposure'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Impute missing BMI values with the median\n",
    "median_value = df_imputed['last_bmi_before_exposure'].median()\n",
    "df_imputed['last_bmi_before_exposure'].fillna(median_value, inplace=True)\n",
    "\n",
    "# Define BMI bins and labels, including an upper boundary for extreme BMIs\n",
    "bins = [0, 18.5, 24.9, 29.9, 34.9, 40, float('inf')]\n",
    "labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese', 'Severely obese', 'Morbidly obese']\n",
    "category_to_numeric = {\n",
    "    'Underweight': 1,\n",
    "    'Normal weight': 2,\n",
    "    'Overweight': 3,\n",
    "    'Obese': 4,\n",
    "    'Severely obese': 5,\n",
    "    'Morbidly obese': 6\n",
    "}\n",
    "\n",
    "# Categorize BMI into ordinal groups\n",
    "df_imputed['last_bmi_before_exposure_category'] = pd.cut(\n",
    "    df_imputed['last_bmi_before_exposure'], bins=bins, labels=labels, right=False\n",
    ")\n",
    "\n",
    "# Check for uncategorized values\n",
    "uncategorized_values = df_imputed[df_imputed['last_bmi_before_exposure_category'].isnull()]\n",
    "print(f\"Number of uncategorized rows: {uncategorized_values.shape[0]}\")\n",
    "\n",
    "# Map BMI categories to numeric ordinal values\n",
    "df_imputed['last_bmi_before_exposure_ordinal'] = df_imputed['last_bmi_before_exposure_category'].map(category_to_numeric)\n",
    "\n",
    "# Ensure BMI ordinal column is numeric\n",
    "df_imputed['last_bmi_before_exposure_ordinal'] = df_imputed['last_bmi_before_exposure_ordinal'].astype(float)\n",
    "\n",
    "# Define covariate columns\n",
    "other_covariates = ['age_at_diagnosis', 'sex', 'ethnic_group', 'race', 'last_bmi_before_exposure_ordinal', 'mapped_insurance_type']\n",
    "covariate_columns = health_covariate_columns + other_covariates\n",
    "\n",
    "# Identify numerical covariates with more than two unique values\n",
    "numerical_covariates = [\n",
    "    col for col in df_imputed[covariate_columns].select_dtypes(include=['float64', 'int64']).columns\n",
    "    if df_imputed[col].nunique() > 2\n",
    "]\n",
    "\n",
    "# Identify binary categorical covariates (exactly two unique values)\n",
    "binary_categorical_covariates = [\n",
    "    col for col in df_imputed[covariate_columns].columns\n",
    "    if df_imputed[col].nunique() == 2\n",
    "]\n",
    "\n",
    "# Identify non-binary categorical covariates\n",
    "categorical_covariates = df_imputed[covariate_columns].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Combine binary and non-binary categorical covariates\n",
    "all_categorical_covariates = categorical_covariates + binary_categorical_covariates\n",
    "\n",
    "# Create imputers for numerical and categorical covariates\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute missing values for numerical covariates\n",
    "df_imputed[numerical_covariates] = median_imputer.fit_transform(df_imputed[numerical_covariates])\n",
    "\n",
    "# Impute missing values for categorical covariates\n",
    "df_imputed[all_categorical_covariates] = mode_imputer.fit_transform(df_imputed[all_categorical_covariates])\n",
    "\n",
    "# Create dummy variables for categorical covariates\n",
    "df_imputed_with_dummies = pd.get_dummies(\n",
    "    df_imputed, columns=categorical_covariates, drop_first=True\n",
    ")\n",
    "\n",
    "# Identify dummy columns (newly created after one-hot encoding)\n",
    "dummy_columns = df_imputed_with_dummies.columns.difference(df_imputed.columns)\n",
    "\n",
    "# Combine binary and dummy columns for covariate analysis\n",
    "categorical_covariate_columns_with_dummies = (\n",
    "    list(df_imputed_with_dummies.columns[df_imputed_with_dummies.columns.isin(all_categorical_covariates)]) +\n",
    "    list(dummy_columns)\n",
    ")\n",
    "\n",
    "# Define a threshold for minimum samples in categorical variables\n",
    "min_samples_threshold = 300\n",
    "sparse_columns = [\n",
    "    col for col in categorical_covariate_columns_with_dummies\n",
    "    if df_imputed_with_dummies[col].value_counts().min() < min_samples_threshold\n",
    "]\n",
    "\n",
    "# Retain non-sparse columns for analysis\n",
    "non_sparse_columns = numerical_covariates + [\n",
    "    col for col in categorical_covariate_columns_with_dummies if col not in sparse_columns\n",
    "]\n",
    "\n",
    "# Drop sparse columns to create the final analysis DataFrame\n",
    "df_analysis = df_imputed_with_dummies.drop(columns=sparse_columns)\n",
    "comorbid_columns = [i for i in comorbidity_before_exposure_table_column_names if i.startswith('before_exposure')]\n",
    "medication_columns = [i for i in medication_column_names if i.startswith('exposure_within_1_year_before_first')]\n",
    "print (len(comorbid_columns))\n",
    "print (len(medication_columns))\n",
    "health_covariate_columns = comorbid_columns + medication_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348607a-1464-40ca-aa74-49bb0c95fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns with NaN values and their count\n",
    "nan_counts = df_analysis.isnull().sum()\n",
    "\n",
    "# Filter only columns with NaN values\n",
    "columns_with_nan = nan_counts[nan_counts > 0]\n",
    "\n",
    "# Display the columns and their counts\n",
    "print(\"Columns with NaN values and their counts:\")\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c1a36-3f01-4be6-97a8-dacfc114afe4",
   "metadata": {},
   "source": [
    "#### no limit on follow-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007cbe7-e215-47ab-906c-197c548b804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "df_analysis = df_analysis[df_analysis['follow_up_post_diagnosis_first_op_exposure'].notnull()]\n",
    "df_analysis = df_analysis[df_analysis['follow_up_post_diagnosis_first_op_exposure']>=0]\n",
    "# Prepare data for lifelines\n",
    "X_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[X_cols].copy()\n",
    "\n",
    "# Add the 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['follow_up_post_diagnosis_first_op_exposure']\n",
    "X_lifelines['event'] = df_analysis['deceased_boolean']\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get hazard ratios and confidence intervals\n",
    "hazard_ratios = cph.hazard_ratios_\n",
    "conf_int = np.exp(cph.confidence_intervals_)\n",
    "\n",
    "# Print hazard ratios and confidence intervals\n",
    "print(\"Hazard Ratios (Exponentiated Coefficients):\")\n",
    "print(hazard_ratios)\n",
    "\n",
    "print(\"\\n95% Confidence Intervals for Hazard Ratios:\")\n",
    "for var in X_cols:\n",
    "    hr = hazard_ratios.get(var, np.nan)\n",
    "    ci_low = conf_int.loc[var, '95% lower-bound'] if var in conf_int.index else np.nan\n",
    "    ci_high = conf_int.loc[var, '95% upper-bound'] if var in conf_int.index else np.nan\n",
    "    print(f\"{var}: {hr:.2f} ({ci_low:.2f}, {ci_high:.2f})\")\n",
    "\n",
    "# Kaplan-Meier estimator plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Iterate over unique groups for survival analysis\n",
    "kmf = KaplanMeierFitter()\n",
    "for value in df_analysis['exposure_group'].unique():\n",
    "    mask = df_analysis['exposure_group'] == value\n",
    "    kmf.fit(durations=df_analysis['follow_up_post_diagnosis_first_op_exposure'][mask],\n",
    "            event_observed=df_analysis['deceased_boolean'][mask],\n",
    "            label=f\"{value} (n = {mask.sum()})\")\n",
    "    \n",
    "    # Plot the Kaplan-Meier curve for this group\n",
    "    kmf.plot_survival_function(ci_show=True)\n",
    "    \n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"Time $t$\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Kaplan-Meier Survival Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826670ae-a129-4ebb-bea6-0b47ac890acc",
   "metadata": {},
   "source": [
    "define outcomes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150db9cd-6716-437d-9e4b-693d85c71088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer outcomes for survival analysis \n",
    "df_analysis['death3000_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 3000), axis=1)\n",
    "df_analysis['death3000_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 3000), axis=1)\n",
    "df_analysis['death14_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 14), axis=1)\n",
    "df_analysis['death14_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 14), axis=1)\n",
    "df_analysis['death28_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 28), axis=1)\n",
    "df_analysis['death28_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 28), axis=1)\n",
    "df_analysis['death30_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 30), axis=1)\n",
    "df_analysis['death30_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 30), axis=1)\n",
    "df_analysis['death60_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 60), axis=1)\n",
    "df_analysis['death60_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 60), axis=1)\n",
    "df_analysis['death90_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 90), axis=1)\n",
    "df_analysis['death90_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 90), axis=1)\n",
    "df_analysis['death180_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 180), axis=1)\n",
    "df_analysis['death180_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 180), axis=1)\n",
    "df_analysis['death365_duration'] = df_analysis.apply(lambda row: get_death_duration_column(row['post_onset_post_opioid_death_days'], 365), axis=1)\n",
    "df_analysis['death365_outcome'] = df_analysis.apply(lambda row: get_death_outcome_column(row['post_onset_post_opioid_death_days'], 365), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08b1dc-09a3-43ea-b976-58f2c9f4ccb6",
   "metadata": {},
   "source": [
    "#### primary analysis : 14 days survival (+ PH assumption test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf996c-16d0-4ae2-b2f7-027c6fbffd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death14_duration']\n",
    "X_lifelines['event'] = df_analysis['death14_outcome']\n",
    "\n",
    "# Verify that columns exist and have no missing values\n",
    "print(X_lifelines[['duration', 'event']].isnull().sum())\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Check proportional hazards assumptions\n",
    "results = cph.check_assumptions(X_lifelines, p_value_threshold=0.05, show_plots=False)\n",
    "\n",
    "# Extract variables that failed the proportional hazards assumption\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "\n",
    "ph_test_results = proportional_hazard_test(cph, X_lifelines, time_transform=\"rank\")\n",
    "failed_variables = ph_test_results.summary[\n",
    "    ph_test_results.summary['p'] < 0.05\n",
    "].index.tolist()\n",
    "\n",
    "print(f\"Variables that failed the proportional hazards assumption: {failed_variables}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0f7d6-3dce-4ef2-9f8f-a7fdd406a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death14_duration']\n",
    "X_lifelines['event'] = df_analysis['death14_outcome']\n",
    "\n",
    "# Verify that columns exist and have no missing values\n",
    "print(X_lifelines[['duration', 'event']].isnull().sum())\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get hazard ratios, confidence intervals, and p-values\n",
    "hazard_ratios = cph.hazard_ratios_\n",
    "conf_int = np.exp(cph.confidence_intervals_)\n",
    "p_values = cph.summary['p']  # Extract p-values from the summary\n",
    "\n",
    "# Function to add stars based on p-value with four levels of significance\n",
    "def significance_stars(p):\n",
    "    if p <= 0.0001:\n",
    "        return '****'  # Very highly statistically significant\n",
    "    elif p <= 0.001:\n",
    "        return '***'  # Highly statistically significant\n",
    "    elif p <= 0.01:\n",
    "        return '**'  # Statistically significant\n",
    "    elif p <= 0.05:\n",
    "        return '*'  # Marginally significant\n",
    "    else:\n",
    "        return ''  # Not statistically significant\n",
    "\n",
    "# Print hazard ratios, confidence intervals, and p-values with stars\n",
    "print(\"Hazard Ratios (Exponentiated Coefficients):\")\n",
    "print(hazard_ratios)\n",
    "\n",
    "print(\"\\n95% Confidence Intervals for Hazard Ratios and Statistical Significance:\")\n",
    "for var in X_lifelines.columns:\n",
    "    hr = hazard_ratios.get(var, np.nan)\n",
    "    ci_low = conf_int.loc[var, '95% lower-bound'] if var in conf_int.index else np.nan\n",
    "    ci_high = conf_int.loc[var, '95% upper-bound'] if var in conf_int.index else np.nan\n",
    "    p_value = p_values.get(var, np.nan)\n",
    "    stars = significance_stars(p_value)\n",
    "    print(f\"{var}: {hr:.2f} ({ci_low:.2f}, {ci_high:.2f}), p-value: {p_value:.4f}{stars}\")\n",
    "\n",
    "# Kaplan-Meier estimator plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Use lifelines KaplanMeierFitter to plot survival curves\n",
    "kmf_list = []  # Store each Kaplan-Meier fitter\n",
    "custom_colors = ['#FF6347', '#4682B4', '#32CD32', '#FFD700']  # Custom colors\n",
    "\n",
    "for i, value in enumerate(df_analysis['exposure_group'].unique()):\n",
    "    mask = df_analysis['exposure_group'] == value\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(\n",
    "        durations=df_analysis['death14_duration'][mask],\n",
    "        event_observed=df_analysis['death14_outcome'][mask],\n",
    "        label=f\"{value} (n = {mask.sum()})\"\n",
    "    )\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True, color=custom_colors[i % len(custom_colors)])\n",
    "    kmf_list.append(kmf)  # Append the fitted Kaplan-Meier object\n",
    "\n",
    "# Add the number at risk table for all groups\n",
    "add_at_risk_counts(*kmf_list, ax=ax )\n",
    "\n",
    "# Finalize the plot\n",
    "plt.ylim(0.5, 1)\n",
    "plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\", fontsize=14)\n",
    "plt.xlabel(\"Time $t$ (days)\", fontsize=14)\n",
    "plt.legend(loc=\"best\", fontsize=12, frameon=False)\n",
    "plt.title(\"14-days Survival Curves by Exposure Group\", fontsize=16)\n",
    "\n",
    "# Save the figure as vector images (SVG and PDF)\n",
    "#plt.savefig(\"../../figures/main_analysis.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"../../figures/main_analysis.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the accuracy using Concordance Index (C-Index)\n",
    "c_index = cph.concordance_index_\n",
    "print(f\"\\nConcordance Index (C-Index): {c_index:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7805bf-1bc1-48d7-ab16-8927eb13d189",
   "metadata": {},
   "source": [
    "#### sensitivity analysis adjusted for variables that failed PH assumption test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a52f6-7528-4743-b751-c330d0ee4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death14_duration']\n",
    "X_lifelines['event'] = df_analysis['death14_outcome']\n",
    "\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event', strata = ['before_exposure_delirium',\n",
    " 'before_exposure_hyperlipidemia',\n",
    " 'before_exposure_schizophrenia_non_mood_psychotic_disorder',\n",
    " 'exposure_within_1_year_before_first_op_acetaminophen',\n",
    " 'exposure_within_1_year_before_first_op_benzodiazepines',\n",
    " 'exposure_within_1_year_before_first_op_insulin',\n",
    " 'exposure_within_1_year_before_first_op_meperidine',\n",
    " 'exposure_within_1_year_before_first_op_topical_anesthetic',\n",
    " 'exposure_within_1_year_before_first_op_warfarin',\n",
    " 'race_White'])\n",
    "\n",
    "# Get hazard ratios, confidence intervals, and p-values\n",
    "hazard_ratios = cph.hazard_ratios_\n",
    "conf_int = np.exp(cph.confidence_intervals_)\n",
    "p_values = cph.summary['p']  # Extract p-values from the summary\n",
    "\n",
    "# Function to add stars based on p-value with four levels of significance\n",
    "def significance_stars(p):\n",
    "    if p <= 0.0001:\n",
    "        return '****'  # Very highly statistically significant\n",
    "    elif p <= 0.001:\n",
    "        return '***'  # Highly statistically significant\n",
    "    elif p <= 0.01:\n",
    "        return '**'  # Statistically significant\n",
    "    elif p <= 0.05:\n",
    "        return '*'  # Marginally significant\n",
    "    else:\n",
    "        return ''  # Not statistically significant\n",
    "\n",
    "# Print hazard ratios, confidence intervals, and p-values with stars\n",
    "print(\"Hazard Ratios (Exponentiated Coefficients):\")\n",
    "print(hazard_ratios)\n",
    "\n",
    "print(\"\\n95% Confidence Intervals for Hazard Ratios and Statistical Significance:\")\n",
    "for var in X_lifelines.columns:\n",
    "    hr = hazard_ratios.get(var, np.nan)\n",
    "    ci_low = conf_int.loc[var, '95% lower-bound'] if var in conf_int.index else np.nan\n",
    "    ci_high = conf_int.loc[var, '95% upper-bound'] if var in conf_int.index else np.nan\n",
    "    p_value = p_values.get(var, np.nan)\n",
    "    stars = significance_stars(p_value)\n",
    "    print(f\"{var}: {hr:.2f} ({ci_low:.2f}, {ci_high:.2f}), p-value: {p_value:.4f}{stars}\")\n",
    "\n",
    "# Kaplan-Meier estimator plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Use lifelines KaplanMeierFitter to plot survival curves\n",
    "kmf_list = []  # Store each Kaplan-Meier fitter\n",
    "custom_colors = ['#FF6347', '#4682B4', '#32CD32', '#FFD700']  # Custom colors\n",
    "\n",
    "for i, value in enumerate(df_analysis['exposure_group'].unique()):\n",
    "    mask = df_analysis['exposure_group'] == value\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(\n",
    "        durations=df_analysis['death14_duration'][mask],\n",
    "        event_observed=df_analysis['death14_outcome'][mask],\n",
    "        label=f\"{value} (n = {mask.sum()})\"\n",
    "    )\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True, color=custom_colors[i % len(custom_colors)])\n",
    "    kmf_list.append(kmf)  # Append the fitted Kaplan-Meier object\n",
    "\n",
    "# Add the number at risk table for all groups\n",
    "add_at_risk_counts(*kmf_list, ax=ax, rows_to_show = ['At risk'])\n",
    "\n",
    "# Set larger font sizes for manuscript publication\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 20,     # Title font size\n",
    "    'axes.labelsize': 18,     # Axis labels font size\n",
    "    'xtick.labelsize': 16,    # X-axis tick labels font size\n",
    "    'ytick.labelsize': 16,    # Y-axis tick labels font size\n",
    "    'legend.fontsize': 16,    # Legend font size\n",
    "    'figure.titlesize': 22    # Overall figure title size\n",
    "})\n",
    "\n",
    "# Finalize the plot with the updated title\n",
    "plt.ylim(0.5, 1)\n",
    "plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\", fontsize=18)\n",
    "plt.xlabel(\"Time $t$ (days)\", fontsize=18)\n",
    "plt.legend(loc=\"best\", fontsize=16, frameon=False)\n",
    "plt.title(\"Kaplan-Meier Survival Curves by Exposure Group Over 14 Days (Adjusted for Variables Violating PH Assumption)\", fontsize=20)\n",
    "\n",
    "# Save the figure as vector images (SVG and PDF)\n",
    "# plt.savefig(\"kaplan_meier_adjusted_ph_assumption.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"../../figures/main_analysis_14days_ph_assumption.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the accuracy using Concordance Index (C-Index)\n",
    "c_index = cph.concordance_index_\n",
    "print(f\"\\nConcordance Index (C-Index): {c_index:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94e1a2-80d9-4964-a08f-f5031e23aef0",
   "metadata": {},
   "source": [
    "#### 60-day survival (to identify 95% confidence interval overlap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ba977-2a07-4954-94fc-ab0ba379e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death60_duration']\n",
    "X_lifelines['event'] = df_analysis['death60_outcome']\n",
    "\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get hazard ratios, confidence intervals, and p-values\n",
    "hazard_ratios = cph.hazard_ratios_\n",
    "conf_int = np.exp(cph.confidence_intervals_)\n",
    "p_values = cph.summary['p']  # Extract p-values from the summary\n",
    "\n",
    "# Function to add stars based on p-value with four levels of significance\n",
    "def significance_stars(p):\n",
    "    if p <= 0.0001:\n",
    "        return '****'  # Very highly statistically significant\n",
    "    elif p <= 0.001:\n",
    "        return '***'  # Highly statistically significant\n",
    "    elif p <= 0.01:\n",
    "        return '**'  # Statistically significant\n",
    "    elif p <= 0.05:\n",
    "        return '*'  # Marginally significant\n",
    "    else:\n",
    "        return ''  # Not statistically significant\n",
    "\n",
    "# Print hazard ratios, confidence intervals, and p-values with stars\n",
    "print(\"Hazard Ratios (Exponentiated Coefficients):\")\n",
    "print(hazard_ratios)\n",
    "\n",
    "print(\"\\n95% Confidence Intervals for Hazard Ratios and Statistical Significance:\")\n",
    "for var in X_lifelines.columns:\n",
    "    hr = hazard_ratios.get(var, np.nan)\n",
    "    ci_low = conf_int.loc[var, '95% lower-bound'] if var in conf_int.index else np.nan\n",
    "    ci_high = conf_int.loc[var, '95% upper-bound'] if var in conf_int.index else np.nan\n",
    "    p_value = p_values.get(var, np.nan)\n",
    "    stars = significance_stars(p_value)\n",
    "    print(f\"{var}: {hr:.2f} ({ci_low:.2f}, {ci_high:.2f}), p-value: {p_value:.4f}{stars}\")\n",
    "# Kaplan-Meier curves for New Users and Consistent Users\n",
    "kmf_new_user = KaplanMeierFitter()\n",
    "kmf_consistent_user = KaplanMeierFitter()\n",
    "\n",
    "# Fit Kaplan-Meier curve for new users\n",
    "mask_new_user = df_analysis['exposure_group'] == 'new user'\n",
    "n_new_user = mask_new_user.sum()  # Sample size for New Users\n",
    "kmf_new_user.fit(\n",
    "    durations=df_analysis['death60_duration'][mask_new_user],\n",
    "    event_observed=df_analysis['death60_outcome'][mask_new_user],\n",
    "    label=f\"New User (n = {n_new_user})\"\n",
    ")\n",
    "\n",
    "# Fit Kaplan-Meier curve for consistent users\n",
    "mask_consistent_user = df_analysis['exposure_group'] == 'consistent user'\n",
    "n_consistent_user = mask_consistent_user.sum()  # Sample size for Consistent Users\n",
    "kmf_consistent_user.fit(\n",
    "    durations=df_analysis['death60_duration'][mask_consistent_user],\n",
    "    event_observed=df_analysis['death60_outcome'][mask_consistent_user],\n",
    "    label=f\"Consistent User (n = {n_consistent_user})\"\n",
    ")\n",
    "\n",
    "# Plot the survival curves\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "kmf_new_user.plot(ax=ax, ci_show=True, color='#FF6347')  # Tomato color for New User\n",
    "kmf_consistent_user.plot(ax=ax, ci_show=True, color='#4682B4')  # SteelBlue color for Consistent User\n",
    "\n",
    "# Add a manual vertical line at 51 days\n",
    "ax.axvline(x=51, color='black', linestyle='--', label='Overlap at 51 Days')\n",
    "\n",
    "# Customize the survival plot\n",
    "ax.set_ylim(0.5, 1)\n",
    "ax.set_title('Kaplan-Meier Survival Curves with Overlap at 51 Days', fontsize=16)\n",
    "ax.set_ylabel('Survival Probability', fontsize=14)\n",
    "ax.set_xlabel('Time (days)', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "\n",
    "# Add at-risk counts below the x-axis\n",
    "max_time = max(kmf_new_user.event_table.index.max(), kmf_consistent_user.event_table.index.max())\n",
    "time_points = np.arange(0, int(max_time) + 1, step=10)\n",
    "at_risk_new_user = [kmf_new_user.event_table.loc[t, 'at_risk'] if t in kmf_new_user.event_table.index else 0 for t in time_points]\n",
    "at_risk_consistent_user = [kmf_consistent_user.event_table.loc[t, 'at_risk'] if t in kmf_consistent_user.event_table.index else 0 for t in time_points]\n",
    "\n",
    "# Adjust the figure to make room for the at-risk table\n",
    "fig.subplots_adjust(bottom=0.3)  # Increase the bottom margin\n",
    "\n",
    "# Add at-risk table\n",
    "y_position_new_user = -0.15  # Adjust position to below the plot\n",
    "y_position_consistent_user = -0.20\n",
    "for i, t in enumerate(time_points):\n",
    "    ax.text(t, y_position_new_user, f\"{at_risk_new_user[i]}\", ha='center', fontsize=13, transform=ax.get_xaxis_transform())  # New User at-risk numbers\n",
    "    ax.text(t, y_position_consistent_user, f\"{at_risk_consistent_user[i]}\", ha='center', fontsize=13, transform=ax.get_xaxis_transform())  # Consistent User at-risk numbers\n",
    "\n",
    "# Add labels for at-risk rows\n",
    "ax.text(-5, y_position_new_user, \"At Risk (New Users):\", fontsize=13, ha='right', transform=ax.get_xaxis_transform())\n",
    "ax.text(-5, y_position_consistent_user, \"At Risk (Consistent Users):\", fontsize=13, ha='right', transform=ax.get_xaxis_transform())\n",
    "\n",
    "# Save the figure as vector images (optional)\n",
    "# plt.savefig(\"kmf_with_overlap_at_51_days.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"../../figures/main_analysis_60days_overlap.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1723c6b-cb80-44e6-888a-7dacca7f5662",
   "metadata": {},
   "source": [
    "#### 180-day survival (to characterize the pattern of survival curves) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731dab6-5f85-4728-988e-62116a31ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for lifelines CoxPHFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death180_duration']\n",
    "X_lifelines['event'] = df_analysis['death180_outcome']\n",
    "\n",
    "\n",
    "# Fit the Cox Proportional Hazards Model using lifelines\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get hazard ratios, confidence intervals, and p-values\n",
    "hazard_ratios = cph.hazard_ratios_\n",
    "conf_int = np.exp(cph.confidence_intervals_)\n",
    "p_values = cph.summary['p']  # Extract p-values from the summary\n",
    "\n",
    "# Function to add stars based on p-value with four levels of significance\n",
    "def significance_stars(p):\n",
    "    if p <= 0.0001:\n",
    "        return '****'  # Very highly statistically significant\n",
    "    elif p <= 0.001:\n",
    "        return '***'  # Highly statistically significant\n",
    "    elif p <= 0.01:\n",
    "        return '**'  # Statistically significant\n",
    "    elif p <= 0.05:\n",
    "        return '*'  # Marginally significant\n",
    "    else:\n",
    "        return ''  # Not statistically significant\n",
    "\n",
    "# Print hazard ratios, confidence intervals, and p-values with stars\n",
    "print(\"Hazard Ratios (Exponentiated Coefficients):\")\n",
    "print(hazard_ratios)\n",
    "\n",
    "print(\"\\n95% Confidence Intervals for Hazard Ratios and Statistical Significance:\")\n",
    "for var in X_lifelines.columns:\n",
    "    hr = hazard_ratios.get(var, np.nan)\n",
    "    ci_low = conf_int.loc[var, '95% lower-bound'] if var in conf_int.index else np.nan\n",
    "    ci_high = conf_int.loc[var, '95% upper-bound'] if var in conf_int.index else np.nan\n",
    "    p_value = p_values.get(var, np.nan)\n",
    "    stars = significance_stars(p_value)\n",
    "    print(f\"{var}: {hr:.2f} ({ci_low:.2f}, {ci_high:.2f}), p-value: {p_value:.4f}{stars}\")\n",
    "\n",
    "# Kaplan-Meier estimator plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Use lifelines KaplanMeierFitter to plot survival curves\n",
    "kmf_list = []  # Store each Kaplan-Meier fitter\n",
    "custom_colors = ['#FF6347', '#4682B4', '#32CD32', '#FFD700']  # Custom colors\n",
    "\n",
    "for i, value in enumerate(df_analysis['exposure_group'].unique()):\n",
    "    mask = df_analysis['exposure_group'] == value\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(\n",
    "        durations=df_analysis['death180_duration'][mask],\n",
    "        event_observed=df_analysis['death180_outcome'][mask],\n",
    "        label=f\"{value} (n = {mask.sum()})\"\n",
    "    )\n",
    "    kmf.plot_survival_function(ax=ax, ci_show=True, color=custom_colors[i % len(custom_colors)])\n",
    "    kmf_list.append(kmf)  # Append the fitted Kaplan-Meier object\n",
    "\n",
    "# Add the number at risk table for all groups\n",
    "add_at_risk_counts(*kmf_list, ax=ax, rows_to_show = ['At risk'])\n",
    "\n",
    "# Set larger font sizes for manuscript publication\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 20,     # Title font size\n",
    "    'axes.labelsize': 18,     # Axis labels font size\n",
    "    'xtick.labelsize': 16,    # X-axis tick labels font size\n",
    "    'ytick.labelsize': 16,    # Y-axis tick labels font size\n",
    "    'legend.fontsize': 16,    # Legend font size\n",
    "    'figure.titlesize': 22    # Overall figure title size\n",
    "})\n",
    "\n",
    "# Finalize the plot with the updated title\n",
    "plt.ylim(0.5, 1)\n",
    "plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\", fontsize=18)\n",
    "plt.xlabel(\"Time $t$ (days)\", fontsize=18)\n",
    "plt.legend(loc=\"best\", fontsize=16, frameon=False)\n",
    "plt.title(\"180 Days Survival Curves by Exposure Group\", fontsize=20)\n",
    "\n",
    "# Save the figure as vector images (SVG and PDF)\n",
    "# plt.savefig(\"kaplan_meier_adjusted_ph_assumption.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"../../figures/main_analysis_180days.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the accuracy using Concordance Index (C-Index)\n",
    "c_index = cph.concordance_index_\n",
    "print(f\"\\nConcordance Index (C-Index): {c_index:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ccdde-9b28-4cc4-a492-51c888f669df",
   "metadata": {},
   "source": [
    "#### 60-day Aalen additive model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b722c-0419-4a7a-807b-d03fbab03b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import AalenAdditiveFitter\n",
    "from lifelines.utils import concordance_index\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for AalenAdditiveFitter\n",
    "x_cols = ['exposure_float'] + non_sparse_columns\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death60_duration']\n",
    "X_lifelines['event'] = df_analysis['death60_outcome']\n",
    "\n",
    "# Fit Aalen's Additive Model using lifelines, focusing on exposure_float\n",
    "aaf = AalenAdditiveFitter(coef_penalizer=0.2)  # Adjust coef_penalizer for regularization if needed\n",
    "aaf.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get the time-varying coefficient (cumulative hazard) for exposure_float\n",
    "time_varying_coef_exposure = aaf.cumulative_hazards_['exposure_float']\n",
    "\n",
    "# Find the time point (date) with the highest hazard coefficient for exposure_float\n",
    "max_time = time_varying_coef_exposure.idxmax()\n",
    "max_value = time_varying_coef_exposure.max()\n",
    "\n",
    "# Print the time point and the highest hazard coefficient\n",
    "print(f\"The time point with the highest hazard coefficient for exposure_float is: {max_time}\")\n",
    "print(f\"The highest hazard coefficient for exposure_float is: {max_value}\")\n",
    "\n",
    "# Predict cumulative hazards for each individual (results in a DataFrame with time on the index)\n",
    "predicted_cumulative_hazards = aaf.predict_cumulative_hazard(X_lifelines)\n",
    "\n",
    "# Interpolate the cumulative hazard for each individual's duration\n",
    "hazard_at_duration = X_lifelines.apply(\n",
    "    lambda row: np.interp(row['duration'], predicted_cumulative_hazards.index, predicted_cumulative_hazards[row.name]), axis=1\n",
    ")\n",
    "\n",
    "# Calculate the concordance index using the predicted hazards\n",
    "ci = concordance_index(X_lifelines['duration'], -hazard_at_duration, X_lifelines['event'])\n",
    "\n",
    "print(f\"Concordance Index: {ci}\")\n",
    "\n",
    "# Plot the time-varying coefficient (cumulative hazard) for exposure_float\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot time-varying coefficient with Tomato color\n",
    "plt.plot(time_varying_coef_exposure.index, time_varying_coef_exposure, \n",
    "         label=\"First-time Opioid Exposure\", color='tomato', linewidth=2)\n",
    "\n",
    "# Highlight the time point with the maximum hazard coefficient with Black color\n",
    "plt.axvline(max_time, color='black', linestyle='--', label=f\"Max Hazard at {max_time}\", linewidth=1.5)\n",
    "\n",
    "# Enhance figure aesthetics for publication\n",
    "plt.xlabel(\"Time $t$ (days)\", fontsize=14)\n",
    "plt.ylabel(\"Cumulative Hazard Coefficient\", fontsize=14)\n",
    "plt.title(\"Time-varying Coefficient for First-time Opioid Exposure in Aalen's Additive Model\", fontsize=16)\n",
    "\n",
    "# Adjust tick parameters for better readability\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Customize the legend\n",
    "plt.legend(loc='best', fontsize=12, frameon=False)\n",
    "\n",
    "# Save the figure as vector images (SVG and PDF)\n",
    "#plt.savefig(\"../figures/time_varying_coefficient_exposure.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "# plt.savefig(\"../../figures/time_varying_coefficient_exposure.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9869f-0e8f-44f7-972a-a5911d869b4e",
   "metadata": {},
   "source": [
    "#### 14-day survival feature importance test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bdfd4-83ae-4824-a6f5-03e2d197b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from lifelines import CoxPHFitter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "# Set font to Helvetica globally for the plot\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Prepare data for Random Survival Forest and Cox model\n",
    "x_cols = ['exposure_float'] + non_sparse_columns  # Include exposure_float in the training\n",
    "X_lifelines = df_analysis[x_cols].copy()\n",
    "\n",
    "# Add 'duration' and 'event' columns\n",
    "X_lifelines['duration'] = df_analysis['death14_duration']\n",
    "X_lifelines['event'] = df_analysis['death14_outcome'].astype(bool)\n",
    "\n",
    "# Normalize 'age_at_diagnosis' to [0, 1] using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_lifelines['age_at_diagnosis'] = scaler.fit_transform(X_lifelines[['age_at_diagnosis']])\n",
    "\n",
    "# Prepare the survival data format for sksurv\n",
    "y = Surv.from_dataframe('event', 'duration', X_lifelines)\n",
    "X = X_lifelines.drop(columns=['duration', 'event'])  # Include exposure_float during training\n",
    "\n",
    "# Ensure all covariates are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "X = X.dropna()\n",
    "\n",
    "# --- Fit the Random Survival Forest ---\n",
    "rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=10, random_state=0)\n",
    "rsf.fit(X, y)\n",
    "\n",
    "# Compute permutation importance\n",
    "perm_importance = permutation_importance(rsf, X, y, n_repeats=10, random_state=0)\n",
    "\n",
    "# --- Fit the Cox Proportional Hazards Model ---\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(X_lifelines, duration_col='duration', event_col='event')\n",
    "\n",
    "# Get the coefficients (log hazard ratios)\n",
    "coefficients = cph.params_\n",
    "\n",
    "# Create a DataFrame to display the importance scores, excluding 'exposure_float' from the plot\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Exclude 'exposure_float' from the plot\n",
    "importance_df = importance_df[importance_df['Variable'] != 'exposure_float']\n",
    "\n",
    "# Map the coefficients to the importance DataFrame for color-coding\n",
    "importance_df['Coefficient'] = importance_df['Variable'].map(coefficients)\n",
    "\n",
    "# Define colors: red for positive coefficients, blue for negative coefficients\n",
    "importance_df['Color'] = np.where(importance_df['Coefficient'] > 0, 'red', 'blue')\n",
    "\n",
    "# Plot the feature importances with color-coding based on the sign of the coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Bar plot with color-coded bars based on the sign of Cox coefficients\n",
    "plt.barh(importance_df['Variable'].head(10), importance_df['Importance'].head(10), \n",
    "         color=importance_df['Color'].head(10))\n",
    "\n",
    "# Enhancing the plot for publication\n",
    "plt.xlabel('Permutation Importance', fontsize=14)\n",
    "plt.title('Top 10 Most Important Features in Random Survival Forest\\n(Colored by Cox Coefficients)', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "\n",
    "# Save the figure as vector images (SVG and PDF)\n",
    "#plt.savefig(\"random_survival_forest_importance_renamed.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"../../figures/random_survival_forest_importance_renamed.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
